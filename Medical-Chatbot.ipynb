{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABHI!\n"
     ]
    }
   ],
   "source": [
    "print(\"ABHI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone # Now this import should work\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"0dff2bc3-3261-4c78-b561-cc33c16289bb\"\n",
    "PINECONE_API_ENV = \"us-east-1-aws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = PyPDFLoader(data) # Use PyPDFLoader directly for a single file\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extracted\n"
     ]
    }
   ],
   "source": [
    "# Use a relative path without the leading slash for local files\n",
    "directory_path = \"Data/Medical-book.pdf\"\n",
    "\n",
    "#Ensure that the cell containing the load_pdf function is executed first\n",
    "from langchain.document_loaders import PyPDFLoader # Import PyPDFLoader from langchain\n",
    "\n",
    "def load_pdf(data):\n",
    "    loader = PyPDFLoader(data) # Use PyPDFLoader directly for a single file\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n",
    "extracted_pdf = load_pdf(directory_path) # Pass the file path to load_pdf\n",
    "print(\"Data Extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks created\n",
      "The number of chunks is: 7020\n"
     ]
    }
   ],
   "source": [
    "#Create text chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter #Import the RecursiveCharacterTextSplitter\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_pdf) # Make sure the function is defined before this line is executed\n",
    "print(\"chunks created\")\n",
    "print(\"The number of chunks is:\",len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document #Import Document class\n",
    "import os # Import the os module\n",
    "\n",
    "# Path to your PDF file\n",
    "# Use a raw string or double backslashes for Windows paths\n",
    "pdf_file = r\"Data/Medical-book.pdf\"\n",
    "#Verify the file path and name for accuracy.\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(pdf_file):\n",
    "    print(f\"Error: File not found at {pdf_file}\")\n",
    "else:\n",
    "    reader = PdfReader(pdf_file)\n",
    "\n",
    "    extracted_data = \"\"\n",
    "    for page in reader.pages:\n",
    "        extracted_data += page.extract_text()\n",
    "\n",
    "    # Now split the extracted text\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "\n",
    "    # Create a Document object\n",
    "    doc = Document(page_content=extracted_data)\n",
    "\n",
    "    # Pass a list of Document objects to split_documents\n",
    "    text_chunks = text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # Import the HuggingFaceEmbeddings class\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7556\\1138245422.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "d:\\ANACONDA\\envs\\mchatbot\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download embedding model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "# Call the function to instantiate the embeddings variable\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "# Now you can access the embeddings variable\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.020386872813105583,\n",
       " 0.02528088353574276,\n",
       " -0.0005662009352818131,\n",
       " 0.011615470983088017,\n",
       " -0.037988364696502686,\n",
       " -0.11998124420642853,\n",
       " 0.041709501296281815,\n",
       " -0.020857175812125206,\n",
       " -0.05900680273771286,\n",
       " 0.024232536554336548,\n",
       " 0.06212019547820091,\n",
       " 0.06767985969781876,\n",
       " 0.03310026600956917,\n",
       " -0.010369333438575268,\n",
       " -0.031215619295835495,\n",
       " -0.032733283936977386,\n",
       " -0.002111728535965085,\n",
       " 0.009261957369744778,\n",
       " -0.12476464360952377,\n",
       " 0.011236833408474922,\n",
       " 0.03904539346694946,\n",
       " 0.054402466863393784,\n",
       " -0.0028255104552954435,\n",
       " 0.04455625265836716,\n",
       " -0.0854201465845108,\n",
       " -0.022873710840940475,\n",
       " 0.039140552282333374,\n",
       " 0.03604690730571747,\n",
       " -0.0321267768740654,\n",
       " -0.06425873190164566,\n",
       " 0.05812908709049225,\n",
       " 0.04669089987874031,\n",
       " 0.08061555027961731,\n",
       " -0.0077342689037323,\n",
       " -0.022083202376961708,\n",
       " 0.06713154911994934,\n",
       " -0.04504143446683884,\n",
       " -0.10212118923664093,\n",
       " 0.0012643759837374091,\n",
       " 0.04680193215608597,\n",
       " 0.02639589086174965,\n",
       " -0.06990959495306015,\n",
       " -0.04453347623348236,\n",
       " -0.006901898421347141,\n",
       " 0.019288599491119385,\n",
       " 0.02059079520404339,\n",
       " 0.006518140435218811,\n",
       " 0.035493891686201096,\n",
       " 0.10393310338258743,\n",
       " 0.01750371791422367,\n",
       " -0.04294285178184509,\n",
       " -0.057037338614463806,\n",
       " -0.011423510499298573,\n",
       " 0.009236752055585384,\n",
       " 0.04582153260707855,\n",
       " 0.0070036184042692184,\n",
       " 0.02421007864177227,\n",
       " -0.06064579635858536,\n",
       " -0.014943967573344707,\n",
       " -0.0305157620459795,\n",
       " -0.06836125254631042,\n",
       " 0.05706855654716492,\n",
       " -0.03227071464061737,\n",
       " 0.04119705408811569,\n",
       " 0.09017682075500488,\n",
       " -0.07689837366342545,\n",
       " -0.022328900173306465,\n",
       " 0.02609133906662464,\n",
       " -0.057754434645175934,\n",
       " -0.060503143817186356,\n",
       " -0.043829482048749924,\n",
       " 0.010114436037838459,\n",
       " 0.03421920910477638,\n",
       " 0.07573983073234558,\n",
       " -0.04518907144665718,\n",
       " 0.005837503354996443,\n",
       " 0.0184907466173172,\n",
       " -0.0018646110547706485,\n",
       " 0.017705997452139854,\n",
       " 0.054946303367614746,\n",
       " 0.06722188740968704,\n",
       " -0.10008065402507782,\n",
       " 0.017738861963152885,\n",
       " 0.043243926018476486,\n",
       " 0.01077823992818594,\n",
       " -0.014706484042108059,\n",
       " -0.013241068460047245,\n",
       " -0.001782232546247542,\n",
       " -0.045426856726408005,\n",
       " -0.03418899327516556,\n",
       " -0.14636532962322235,\n",
       " -0.011157987639307976,\n",
       " -0.011241820640861988,\n",
       " 0.011740676127374172,\n",
       " -0.08864285796880722,\n",
       " -0.028394203633069992,\n",
       " 0.07532472908496857,\n",
       " -0.018445875495672226,\n",
       " -0.17038744688034058,\n",
       " 0.15587182343006134,\n",
       " 0.022921469062566757,\n",
       " 0.046667248010635376,\n",
       " 0.040010735392570496,\n",
       " 0.02375500649213791,\n",
       " 0.049802809953689575,\n",
       " 0.030321596190333366,\n",
       " 0.0003741529362741858,\n",
       " 0.06957260519266129,\n",
       " -0.022312656044960022,\n",
       " -0.02747281827032566,\n",
       " 0.006083943415433168,\n",
       " -0.04853246361017227,\n",
       " 0.049238789826631546,\n",
       " -0.007612141780555248,\n",
       " 0.06917710602283478,\n",
       " -0.07174898684024811,\n",
       " -0.020257242023944855,\n",
       " 0.014374688267707825,\n",
       " -0.030236804857850075,\n",
       " 0.004180468153208494,\n",
       " 0.05348922684788704,\n",
       " -0.058872416615486145,\n",
       " 0.023056630045175552,\n",
       " 0.013102822005748749,\n",
       " 0.01088209543377161,\n",
       " 0.02322239615023136,\n",
       " 0.028361210599541664,\n",
       " -3.843664856439317e-33,\n",
       " 0.0435662642121315,\n",
       " -0.003594552166759968,\n",
       " 0.042123064398765564,\n",
       " 0.1231817975640297,\n",
       " 0.017473308369517326,\n",
       " 0.00942733883857727,\n",
       " -0.09451454132795334,\n",
       " -0.021238375455141068,\n",
       " 0.03426387161016464,\n",
       " 0.025959163904190063,\n",
       " 0.028061239048838615,\n",
       " 0.012698487378656864,\n",
       " -0.04617796093225479,\n",
       " 0.030305471271276474,\n",
       " -0.045230939984321594,\n",
       " 0.11220850050449371,\n",
       " -0.09135962277650833,\n",
       " -0.013798639178276062,\n",
       " 0.025815125554800034,\n",
       " 0.08335626125335693,\n",
       " -0.07693815231323242,\n",
       " -0.010359508916735649,\n",
       " 0.009555504657328129,\n",
       " 0.08872868865728378,\n",
       " -0.009140676818788052,\n",
       " 0.008417350240051746,\n",
       " 0.010792146436870098,\n",
       " -0.09071637690067291,\n",
       " 0.09623939543962479,\n",
       " 0.007239796221256256,\n",
       " -0.03825897350907326,\n",
       " -0.05111745372414589,\n",
       " 0.020446274429559708,\n",
       " 0.01577543467283249,\n",
       " -0.00584018137305975,\n",
       " 0.011155584827065468,\n",
       " -0.007191200274974108,\n",
       " -0.07329276949167252,\n",
       " -0.07283007353544235,\n",
       " -0.006110389716923237,\n",
       " -0.05931411683559418,\n",
       " 0.045463789254426956,\n",
       " 0.04360096901655197,\n",
       " -0.007337683811783791,\n",
       " -0.02558256685733795,\n",
       " -0.0344063900411129,\n",
       " 0.02559274062514305,\n",
       " 0.018136944621801376,\n",
       " 0.04025298357009888,\n",
       " 0.03997461870312691,\n",
       " -0.04333764687180519,\n",
       " 0.008319374173879623,\n",
       " -0.03883630037307739,\n",
       " 0.05585148185491562,\n",
       " -0.010561023838818073,\n",
       " 0.01699744537472725,\n",
       " 0.04742543399333954,\n",
       " -0.048003457486629486,\n",
       " -0.013104816898703575,\n",
       " 0.046607110649347305,\n",
       " -0.003912207204848528,\n",
       " 0.10242760181427002,\n",
       " -0.04255157709121704,\n",
       " -0.028219876810908318,\n",
       " -0.008180612698197365,\n",
       " -0.01885264366865158,\n",
       " 0.05203333869576454,\n",
       " 0.033868011087179184,\n",
       " 0.059511031955480576,\n",
       " 0.004061603918671608,\n",
       " -0.01956753432750702,\n",
       " 0.02674257941544056,\n",
       " 0.02093179151415825,\n",
       " 0.02192043699324131,\n",
       " 0.012750852853059769,\n",
       " 0.05398520082235336,\n",
       " 0.052067991346120834,\n",
       " -0.0031074492726475,\n",
       " 0.02487236261367798,\n",
       " -0.07944536954164505,\n",
       " 0.028617681935429573,\n",
       " -0.0007746760384179652,\n",
       " -0.003381764981895685,\n",
       " -0.05178724229335785,\n",
       " 0.09358307719230652,\n",
       " 0.018984489142894745,\n",
       " -0.009582558646798134,\n",
       " -0.0856575071811676,\n",
       " -0.017498208209872246,\n",
       " -0.004158390685915947,\n",
       " -0.06506012380123138,\n",
       " 0.05912616476416588,\n",
       " 0.035769641399383545,\n",
       " -0.005036777351051569,\n",
       " -0.08909005671739578,\n",
       " 2.5757033649164638e-33,\n",
       " 0.13979335129261017,\n",
       " 0.017513630911707878,\n",
       " -0.05452438071370125,\n",
       " -0.06710045784711838,\n",
       " -0.010243951342999935,\n",
       " -0.032303180545568466,\n",
       " -0.07818872481584549,\n",
       " 0.14000575244426727,\n",
       " -0.07843434065580368,\n",
       " 0.0474369153380394,\n",
       " 0.021780453622341156,\n",
       " 0.021539803594350815,\n",
       " 0.1262277364730835,\n",
       " 0.02580106630921364,\n",
       " 0.022561756893992424,\n",
       " -0.015236180275678635,\n",
       " 0.13175277411937714,\n",
       " 0.014995898120105267,\n",
       " 0.014494264498353004,\n",
       " -0.0018083483446389437,\n",
       " -0.013143729418516159,\n",
       " -0.049164507538080215,\n",
       " -0.06190984323620796,\n",
       " 0.021932406350970268,\n",
       " -0.022566061466932297,\n",
       " 0.024125924333930016,\n",
       " 0.04778725281357765,\n",
       " 0.001361499889753759,\n",
       " -0.12093906104564667,\n",
       " 0.013258987106382847,\n",
       " -0.015382496640086174,\n",
       " 0.028439369052648544,\n",
       " -0.031059566885232925,\n",
       " -0.014658545143902302,\n",
       " -0.0164962001144886,\n",
       " 0.023634258657693863,\n",
       " -0.0965748280286789,\n",
       " -0.038894761353731155,\n",
       " -0.02935647778213024,\n",
       " -0.031149519607424736,\n",
       " -0.04675932228565216,\n",
       " 0.01085135992616415,\n",
       " -0.006681295111775398,\n",
       " 0.030533554032444954,\n",
       " -0.10486804693937302,\n",
       " -0.005622635595500469,\n",
       " -0.03426210954785347,\n",
       " 0.014524451456964016,\n",
       " -0.036871835589408875,\n",
       " -0.03581416606903076,\n",
       " -0.09492850303649902,\n",
       " -0.05121384561061859,\n",
       " 0.0863681212067604,\n",
       " -0.02769472263753414,\n",
       " -0.03255052864551544,\n",
       " 0.03351925313472748,\n",
       " -0.023608211427927017,\n",
       " -0.0033292206935584545,\n",
       " 0.03848697617650032,\n",
       " -0.0116463303565979,\n",
       " 0.012732136063277721,\n",
       " 0.05946173891425133,\n",
       " 0.03451535105705261,\n",
       " 0.08603373914957047,\n",
       " 0.025225210934877396,\n",
       " -0.03410428389906883,\n",
       " 0.01370932161808014,\n",
       " 0.015575790777802467,\n",
       " 0.03082992695271969,\n",
       " -0.0181691013276577,\n",
       " 0.0075484346598386765,\n",
       " 0.00767799187451601,\n",
       " -0.020997334271669388,\n",
       " -0.01683652587234974,\n",
       " -0.032185547053813934,\n",
       " 0.06366591155529022,\n",
       " 0.003027765080332756,\n",
       " -0.01919621229171753,\n",
       " 0.01796714961528778,\n",
       " 0.030703270807862282,\n",
       " -0.010722151026129723,\n",
       " 0.0567406490445137,\n",
       " 0.02326800301671028,\n",
       " 0.029091518372297287,\n",
       " 0.007758266758173704,\n",
       " 0.06784671545028687,\n",
       " 0.08166711777448654,\n",
       " 0.047504521906375885,\n",
       " -0.0262406338006258,\n",
       " -0.042831819504499435,\n",
       " -0.009907595813274384,\n",
       " 0.006457660812884569,\n",
       " 0.017302438616752625,\n",
       " 0.030671026557683945,\n",
       " -0.03801177814602852,\n",
       " -1.6864364127400222e-08,\n",
       " -0.08774770051240921,\n",
       " 0.03914780169725418,\n",
       " -0.007313665002584457,\n",
       " 0.055220186710357666,\n",
       " 0.03042862005531788,\n",
       " 0.018359912559390068,\n",
       " -0.08776683360338211,\n",
       " -0.06734011322259903,\n",
       " -0.0747460424900055,\n",
       " -0.009306997992098331,\n",
       " 0.03774425759911537,\n",
       " 0.13193342089653015,\n",
       " -0.08082900196313858,\n",
       " 0.01321407500654459,\n",
       " 0.048574961721897125,\n",
       " 0.09028726816177368,\n",
       " -0.029366280883550644,\n",
       " 0.03968300297856331,\n",
       " -0.0341360829770565,\n",
       " 0.0035193762741982937,\n",
       " -0.011343852616846561,\n",
       " 0.009339207783341408,\n",
       " 0.011233095079660416,\n",
       " -0.06465622037649155,\n",
       " 0.0345761775970459,\n",
       " -0.09496650844812393,\n",
       " -0.007475709542632103,\n",
       " 0.003689560340717435,\n",
       " 0.010514314286410809,\n",
       " -0.06667248904705048,\n",
       " 0.051605112850666046,\n",
       " 0.10477923601865768,\n",
       " -0.05478629842400551,\n",
       " 0.021519236266613007,\n",
       " -0.08572050929069519,\n",
       " -0.027919678017497063,\n",
       " 0.02723752148449421,\n",
       " 0.09629359841346741,\n",
       " 0.06709317862987518,\n",
       " -0.07181668281555176,\n",
       " -0.09750431030988693,\n",
       " 0.04430799558758736,\n",
       " -0.05396273732185364,\n",
       " -0.10748161375522614,\n",
       " -0.05498868227005005,\n",
       " 0.03482293710112572,\n",
       " 0.06672007590532303,\n",
       " -0.05602458119392395,\n",
       " 0.02175173908472061,\n",
       " -0.06315217912197113,\n",
       " -0.06730655580759048,\n",
       " 0.03782231733202934,\n",
       " 0.07897446304559708,\n",
       " 0.002572576981037855,\n",
       " 0.10580893605947495,\n",
       " 0.09685958921909332,\n",
       " 0.047380004078149796,\n",
       " 0.03066212125122547,\n",
       " -0.008867030031979084,\n",
       " 0.06080889329314232,\n",
       " 0.030900919809937477,\n",
       " -0.030652379617094994,\n",
       " 0.03755692020058632,\n",
       " 0.03742789104580879]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It seems like you meant to use the variable embeddings that you defined earlier.\n",
    "query_result = embeddings.embed_query(\"Hello World!\")\n",
    "print(\"Length:\", len(query_result))\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACONDA\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0dff2bc3-3261-4c78-b561-cc33c16289bb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Ensure the API key is available in the environment\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"0dff2bc3-3261-4c78-b561-cc33c16289bb\"  \n",
    "os.environ['PINECONE_API_ENV'] = \"us-east-1-aws\" \n",
    "\n",
    "# Print the API key directly to check its value and presence\n",
    "print(os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Initialize Pinecone using the Pinecone class\n",
    "pc = Pinecone(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\"),\n",
    "    environment=os.environ.get(\"PINECONE_API_ENV\")\n",
    ")\n",
    "\n",
    "# Check for existing indexes or create a new one if needed\n",
    "if 'medical-chatbot' not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name='medical-chatbot',  # Use 'name' instead of 'index_name'\n",
    "        dimension=384,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Now, connect to the index and use it\n",
    "index = pc.Index('medical-chatbot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4972\\3216035817.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "d:\\ANACONDA\\envs\\mchatbot\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Pinecone  # Correct import\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# Initialize embeddings with a specific model\n",
    "# that produces embeddings of the correct dimension (384)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Assuming you have already created an index named 'medical-chatbot'\n",
    "# and have an embeddings object named 'embeddings' (e.g., from HuggingFaceEmbeddings)\n",
    "# The line below was missing the Pinecone initialization\n",
    "index_name = 'medical-chatbot' # make sure you have created an index with this name\n",
    "docsearch = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "\n",
    "# After having my index, we can load it like this -\n",
    "# The line below was corrected to use the variable 'embeddings'\n",
    "docsearch = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate # import PromptTemplate\n",
    "\n",
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers # Import the CTransformers class from langchain.llms\n",
    "from huggingface_hub import hf_hub_download\n",
    "# Download and save the model locally\n",
    "model_path = hf_hub_download(repo_id=\"TheBloke/Llama-2-7B-Chat-GGML\",\n",
    "                             filename=\"llama-2-7b-chat.ggmlv3.q4_0.bin\")\n",
    "\n",
    "# Now use the local path to the model\n",
    "llm = CTransformers(\n",
    "    model = model_path,\n",
    "    model_type=\"llama\",\n",
    "    config={\"max_new_tokens\":512, \"temperature\":0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA \n\u001b[0;32m      3\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[0;32m      4\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m      5\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 6\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m \u001b[43mdocsearch\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m2\u001b[39m}),\n\u001b[0;32m      7\u001b[0m     return_source_documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     chain_type_kwargs\u001b[38;5;241m=\u001b[39mchain_type_kwargs\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docsearch' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA \n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever= docsearch.as_retriever(search_kwargs={\"k\":2}),\n",
    "    return_source_documents = True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Prompt: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mqa\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input})\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Input Prompt: \")\n",
    "    result = qa({\"query\": user_input})\n",
    "    print(\"Response:\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
